# server.py
import os
import gc
import sys
import time
import asyncio
import tempfile
import logging
from pathlib import Path
from typing import Optional
from contextlib import asynccontextmanager

# å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
sys.stdout.reconfigure(line_buffering=True)

# Nuitka/PyInstaller è¡¥ä¸ - å¿…é¡»æ”¾åœ¨ funasr å¯¼å…¥ä¹‹å‰
if getattr(sys, 'frozen', False):
    # åˆ›å»ºç¼ºå¤±çš„ version.txt
    # æ”¯æŒ Nuitka å’Œ PyInstaller çš„ä¸åŒè·¯å¾„
    if hasattr(sys, '_MEIPASS'):
        # PyInstaller è·¯å¾„
        base_dir = sys._MEIPASS
    else:
        # Nuitka è·¯å¾„ï¼ˆé€šå¸¸æ˜¯å¯æ‰§è¡Œæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼‰
        base_dir = os.path.dirname(sys.executable)
    
    funasr_dir = os.path.join(base_dir, 'funasr')
    os.makedirs(funasr_dir, exist_ok=True)
    version_file = os.path.join(funasr_dir, 'version.txt')
    if not os.path.exists(version_file):
        with open(version_file, 'w') as f:
            f.write('1.2.7')
        print(f"âœ… åˆ›å»º funasr version.txt: {version_file}", flush=True)

# è®¾ç½®æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯• Tauri sidecarï¼‰
def setup_logging():
    """è®¾ç½®æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶"""
    from datetime import datetime
    
    # ç¡®å®šæ—¥å¿—ç›®å½•
    if getattr(sys, 'frozen', False):
        # æ‰“åŒ…åçš„è·¯å¾„
        exe_dir = Path(sys.executable).parent
        if exe_dir.name == "MacOS":
            # macOS App åŒ…ç»“æ„ï¼Œæ—¥å¿—æ”¾åœ¨ App åŒçº§ç›®å½•
            log_dir = exe_dir.parent.parent.parent / "logs"
        else:
            log_dir = exe_dir / "logs"
    else:
        # å¼€å‘ç¯å¢ƒ
        log_dir = Path(__file__).parent / "logs"
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir.mkdir(exist_ok=True)
    
    # æ—¥å¿—æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    log_file = log_dir / f"server_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    # é‡å®šå‘æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯
    class Logger:
        def __init__(self, filename):
            self.terminal = sys.stdout
            self.log = open(filename, "a", encoding='utf-8')
        
        def write(self, message):
            self.terminal.write(message)
            self.log.write(message)
            self.log.flush()  # ç«‹å³å†™å…¥ç£ç›˜
        
        def flush(self):
            self.terminal.flush()
            self.log.flush()
        
        def isatty(self):
            return self.terminal.isatty()
        
        def fileno(self):
            return self.terminal.fileno()
    
    # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
    sys.stdout = Logger(log_file)
    sys.stderr = Logger(log_file)
    
    print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶ä½ç½®: {log_file}")
    print("=" * 70)
    
    return log_file

# åœ¨æ‰“åŒ…ç¯å¢ƒä¸‹å¯ç”¨æ—¥å¿—
if getattr(sys, 'frozen', False):
    setup_logging()

from fastapi import FastAPI, File, UploadFile, Form, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware

from funasr_onnx import SenseVoiceSmall as ONNXSenseVoiceSmall
from funasr_onnx.utils.postprocess_utils import rich_transcription_postprocess

print("âœ… ONNX è¿è¡Œæ—¶åŠ è½½æˆåŠŸ", flush=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

app = FastAPI(title="SenseVoice ONNX API")

# æ·»åŠ CORSæ”¯æŒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€æ¨¡å‹å˜é‡å’Œä¿¡å·é‡
model = None
# é™åˆ¶å¹¶å‘è¯·æ±‚æ•°é‡
SEMAPHORE = asyncio.Semaphore(3)  # æœ€å¤šåŒæ—¶å¤„ç†3ä¸ªè¯·æ±‚

# âœ… çº¯ONNXè®¾å¤‡æ£€æµ‹å‡½æ•°
def get_available_device():
    """æ£€æµ‹å¯ç”¨è®¾å¤‡ï¼ˆçº¯ONNXç‰ˆæœ¬ï¼‰"""
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        
        if 'CUDAExecutionProvider' in providers:
            print("ğŸš€ æ£€æµ‹åˆ°CUDAæ”¯æŒ", flush=True)
            return "cuda"
        elif 'CoreMLExecutionProvider' in providers:
            print("ğŸ æ£€æµ‹åˆ°CoreMLæ”¯æŒ", flush=True)
            return "coreml"
        else:
            print("ğŸ’» ä½¿ç”¨CPU", flush=True)
            return "cpu"
    except:
        print("ğŸ’» é»˜è®¤ä½¿ç”¨CPU", flush=True)
        return "cpu"


def get_model_path():
    """è·å–æ¨¡å‹è·¯å¾„ï¼ˆæ”¯æŒPyInstalleræ‰“åŒ…å’Œå¤–éƒ¨æ¨¡å‹æ–‡ä»¶å¤¹ï¼‰"""
    
    # 1. ä¼˜å…ˆæ£€æŸ¥å¤–éƒ¨æ¨¡å‹æ–‡ä»¶å¤¹ï¼ˆä¸å¯æ‰§è¡Œæ–‡ä»¶åŒçº§ï¼‰
    if getattr(sys, 'frozen', False):
        # æ‰“åŒ…åçš„è·¯å¾„ï¼šå¯æ‰§è¡Œæ–‡ä»¶æ‰€åœ¨ç›®å½•
        exe_dir = Path(sys.executable).parent
        # å¯¹äºmacOS .appï¼Œéœ€è¦å‘ä¸Šæ‰¾åˆ°Contentsç›®å½•çš„çˆ¶ç›®å½•
        if exe_dir.name == "MacOS" and exe_dir.parent.name == "Contents":
            # ä» .app/Contents/MacOS å‘ä¸Šåˆ° .app çš„åŒçº§ç›®å½•
            app_parent = exe_dir.parent.parent.parent
            external_models_path = app_parent / "models"
            if external_models_path.exists():
                print(f"âœ… ä½¿ç”¨å¤–éƒ¨æ¨¡å‹æ–‡ä»¶å¤¹: {external_models_path}", flush=True)
                return external_models_path
        
        # å¸¸è§„è·¯å¾„ï¼ˆWindows/Linux æˆ–ç›´æ¥è¿è¡Œï¼‰
        external_models_path = exe_dir / "models"
        if external_models_path.exists():
            print(f"âœ… ä½¿ç”¨å¤–éƒ¨æ¨¡å‹æ–‡ä»¶å¤¹: {external_models_path}", flush=True)
            return external_models_path
    else:
        # å¼€å‘ç¯å¢ƒï¼šæ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•çš„å¤–éƒ¨modelsæ–‡ä»¶å¤¹
        project_root = Path(__file__).parent.parent
        external_models_path = project_root / "models"
        if external_models_path.exists():
            print(f"âœ… ä½¿ç”¨å¤–éƒ¨æ¨¡å‹æ–‡ä»¶å¤¹: {external_models_path}", flush=True)
            return external_models_path
    
    # 2. æ£€æŸ¥æ‰“åŒ…å†…ç½®çš„æ¨¡å‹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if getattr(sys, 'frozen', False):
        base_path = Path(sys._MEIPASS)
        models_path = base_path / "models"
        if models_path.exists():
            print(f"âœ… ä½¿ç”¨å†…ç½®æ¨¡å‹æ–‡ä»¶å¤¹: {models_path}", flush=True)
            return models_path
    
    # 3. å¼€å‘ç¯å¢ƒè·¯å¾„
    current_dir = Path(__file__).parent
    models_path = current_dir / "models"
    if models_path.exists():
        print(f"âœ… ä½¿ç”¨å¼€å‘ç¯å¢ƒæ¨¡å‹æ–‡ä»¶å¤¹: {models_path}", flush=True)
        return models_path
    
    # 4. å›é€€åˆ°é»˜è®¤ç¼“å­˜ç›®å½•ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰
    print("âš ï¸  æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹æ–‡ä»¶å¤¹ï¼Œå°†ä½¿ç”¨åœ¨çº¿æ¨¡å‹", flush=True)
    return None

def init_model():
    """åˆå§‹åŒ–æ¨¡å‹"""
    global model
    try:
        print("=" * 70, flush=True)
        print("ğŸš€ å¼€å§‹åˆå§‹åŒ– SenseVoice è¯­éŸ³è¯†åˆ«æ¨¡å‹", flush=True)
        
        # âœ… ä½¿ç”¨çº¯ONNXè®¾å¤‡æ£€æµ‹
        device = get_available_device()
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}", flush=True)

        # è·å–æ¨¡å‹è·¯å¾„
        models_path = get_model_path()
        
        if not models_path:
            print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶å¤¹ï¼Œè¯·ç¡®ä¿modelsç›®å½•å­˜åœ¨", flush=True)
            return False

        print(f"ğŸ“‚ ä½¿ç”¨æœ¬åœ°ONNXæ¨¡å‹: {models_path}", flush=True)
        print("=" * 70, flush=True)

        # åˆå§‹åŒ–æ¨¡å‹
        print("â³ æ­£åœ¨åŠ è½½æ¨¡å‹åˆ°å†…å­˜ï¼Œè¯·ç¨å€™...", flush=True)
        start_time = time.time()
        
        # æ·»åŠ è¯¦ç»†çš„é”™è¯¯è¿½è¸ª
        import traceback
        import sys
        
        try:
            # åªä½¿ç”¨ ONNX æ¨¡å‹
            print("ğŸš€ ä½¿ç”¨ ONNX åŠ é€Ÿæ¨¡å‹", flush=True)
            
            # æ£€æŸ¥ONNXæ¨¡å‹è·¯å¾„ï¼ˆåµŒå¥—ç›®å½•ï¼‰
            onnx_model_path = models_path / "models" / "iic" / "SenseVoiceSmall"
            if not onnx_model_path.exists():
                # å°è¯•éåµŒå¥—è·¯å¾„
                onnx_model_path = models_path / "iic" / "SenseVoiceSmall"
            
            if not onnx_model_path.exists():
                print(f"âŒ ONNXæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {onnx_model_path}", flush=True)
                return False
                
            onnx_quant_path = onnx_model_path / "model_quant.onnx"
            onnx_path = onnx_model_path / "model.onnx"
            
            # ONNXæ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†ITNï¼Œæ— éœ€é¢å¤–é…ç½®æ–‡ä»¶
            
            # è®¾å¤‡å·²åœ¨ä¸Šé¢æ£€æµ‹è¿‡äº†
            print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}", flush=True)
            
            if onnx_quant_path.exists():
                print(f"ğŸ”¥ ä½¿ç”¨é‡åŒ–ONNXæ¨¡å‹ï¼ˆæœ€å¿«ï¼‰", flush=True)
                model = ONNXSenseVoiceSmall(
                    str(onnx_model_path),
                    batch_size=1,
                    quantize=False,
                    device=device,
                    intra_op_num_threads=8  # é™åˆ¶çº¿ç¨‹æ•°ï¼Œé˜²æ­¢CPUè¿‡è½½
                )
            elif onnx_path.exists():
                print(f"âš¡ ä½¿ç”¨æ ‡å‡†ONNXæ¨¡å‹", flush=True)
                model = ONNXSenseVoiceSmall(
                    str(onnx_model_path),
                    batch_size=1,
                    quantize=False,  # å¯ç”¨é‡åŒ–ä»¥ä¼˜åŒ–æ€§èƒ½
                    device=device,
                    intra_op_num_threads=8  # é™åˆ¶çº¿ç¨‹æ•°ï¼Œé˜²æ­¢CPUè¿‡
                )
            else:
                print(f"âŒ æœªæ‰¾åˆ°ONNXæ¨¡å‹æ–‡ä»¶ (model.onnx æˆ– model_quant.onnx)", flush=True)
                return False
            
            print("âœ… ONNXæ¨¡å‹åŠ è½½å®Œæˆ", flush=True)
            
            load_time = time.time() - start_time
            print(f"â±ï¸  æ¨¡å‹åŠ è½½å®Œæˆï¼è€—æ—¶: {load_time:.2f} ç§’", flush=True)
            
        except Exception as e:
            print(f"âŒ ONNXæ¨¡å‹åŠ è½½å¤±è´¥: {e}", flush=True)
            import traceback
            traceback.print_exc()
            return False
        
        print("=" * 70, flush=True)
        print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼æœåŠ¡å‡†å¤‡å°±ç»ª", flush=True)
        print("ğŸŒ APIåœ°å€: http://localhost:8001", flush=True)
        print("=" * 70, flush=True)
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}", flush=True)
        logger.error(f"Failed to initialize model: {e}")
        return False


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨¡å‹"""
    if not init_model():
        logger.error("Failed to initialize model")


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "model_type": "ONNX",
        "device": get_available_device()
    }


async def cleanup_temp_file(file_path: str):
    """å¼‚æ­¥æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    await asyncio.sleep(1)  # çŸ­æš‚å»¶è¿Ÿç¡®ä¿æ–‡ä»¶ä½¿ç”¨å®Œæ¯•
    try:
        os.unlink(file_path)
    except:
        pass

@app.post("/transcribe/normal")
async def transcribe_normal(
        background_tasks: BackgroundTasks,
        file: UploadFile = File(...),
        language: Optional[str] = Form("auto"),
        use_itn: Optional[bool] = Form(True)
):
    """
    è½¬å½•æ¥å£
    """
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")

    # æ–‡ä»¶å¤§å°é™åˆ¶
    file_size = 0
    contents = b""
    chunk_size = 8192
    max_size = 100 * 1024 * 1024  # 100MB
    
    while True:
        chunk = await file.read(chunk_size)
        if not chunk:
            break
        file_size += len(chunk)
        if file_size > max_size:
            raise HTTPException(status_code=413, detail="File too large")
        contents += chunk

    # ä¿¡å·é‡é™åˆ¶å¹¶å‘
    async with SEMAPHORE:
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as tmp:
            tmp.write(contents)
            tmp_path = tmp.name

        # æ·»åŠ åå°ä»»åŠ¡æ¸…ç†æ–‡ä»¶
        background_tasks.add_task(cleanup_temp_file, tmp_path)

        try:
            # ä½¿ç”¨ONNXæ¨¡å‹æ¨ç†
            print("ğŸš€ ä½¿ç”¨ONNXå¿«é€Ÿæ¨ç†", flush=True)
            res = model(
                [tmp_path],  # ONNXæ¨¡å‹éœ€è¦åˆ—è¡¨æ ¼å¼
                language=language if language != "auto" else "auto",
                textnorm="withitn" if use_itn else "woitn"  # ONNXä½¿ç”¨textnormå‚æ•°
            )
            
            if res and len(res) > 0:
                # ONNXç‰ˆæœ¬ç›´æ¥è¿”å›å¤„ç†åçš„æ–‡æœ¬å­—ç¬¦ä¸²
                raw_text = res[0] if isinstance(res[0], str) else str(res[0])
                
                # ä½¿ç”¨ONNXç‰ˆæœ¬çš„åå¤„ç†å‡½æ•°ï¼ˆå·²ç»åŒ…å«ITNå¤„ç†ï¼‰
                text = rich_transcription_postprocess(raw_text)
                
                print(f"ğŸ“ ONNXè¯†åˆ«ç»“æœ: {text}", flush=True)
                
                return {
                    "text": text,
                    "filename": file.filename,
                    "language": language
                }
            else:
                raise HTTPException(status_code=500, detail="ONNXæ¨ç†æ— ç»“æœ")

        except FileNotFoundError as e:
            logger.error(f"ğŸ“ ä¸´æ—¶æ–‡ä»¶æœªæ‰¾åˆ°: {tmp_path}, é”™è¯¯: {e}")
            raise HTTPException(status_code=500, detail="æ–‡ä»¶å¤„ç†é”™è¯¯")
        except ImportError as e:
            logger.error(f"ğŸ“¦ æ¨¡å‹ä¾èµ–ç¼ºå¤±: {e}")
            raise HTTPException(status_code=503, detail="æ¨¡å‹ä¾èµ–é”™è¯¯")
        except Exception as e:
            import traceback
            logger.error(f"âŒ è½¬å½•å¤±è´¥è¯¦æƒ…:")
            logger.error(f"   ğŸ“„ æ–‡ä»¶å: {file.filename}")
            logger.error(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} bytes")
            logger.error(f"   ğŸŒ è¯­è¨€: {language}, ä½¿ç”¨ITN: {use_itn}")
            logger.error(f"   ğŸ·ï¸  é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   ğŸ’¬ é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(f"   ğŸ“š å®Œæ•´å †æ ˆ:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    logger.error(f"     {line}")
            raise HTTPException(status_code=500, detail=f"è½¬å½•å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    from datetime import datetime
    
    print("\n" + "ğŸ¤" * 35 + "\n", flush=True)
    print("ğŸš€ å¯åŠ¨ Ohoo SenseVoice è¯­éŸ³è¯†åˆ«æœåŠ¡...", flush=True)
    print(f"ğŸ“… å¯åŠ¨æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}", flush=True)
    print("\n" + "ğŸ¤" * 35 + "\n", flush=True)
    
    # è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ Pythonç‰ˆæœ¬: {sys.version}", flush=True)
    print(f"ğŸ“ å·¥ä½œç›®å½•: {os.getcwd()}", flush=True)
    print(f"ğŸš€ å¯æ‰§è¡Œæ–‡ä»¶: {sys.executable}", flush=True)
    print(f"ğŸ“¦ æ˜¯å¦æ‰“åŒ…: {getattr(sys, 'frozen', False)}", flush=True)
    print(f"ğŸ’¾ è®¾å¤‡: {get_available_device()}", flush=True)
    
    # æ¨¡å‹è·¯å¾„è°ƒè¯•
    model_path = get_model_path()
    print(f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {model_path}", flush=True)
    
    print("=" * 70, flush=True)
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=1758,
        log_level="info",
        access_log=True
    )